「越來越多人在社群網站上發布並轉貼新聞連結和資訊，我們希望可以量化人們所分享的、不同立場的新聞內容種類，以及人們在何種程度會實際閱讀它。」臉書（Facebook）數據科學家梅辛（Solomon Messing）全球最多使用者的社群網站臉書（Facebook）內部研究人員正進行一項調查，考量臉書是否有必要為用戶過濾不同立場的政治新聞內容。調查顯示，臉書的「新聞發表演算法（news feed algorithm）」試圖篩選出一些具有挑戰性的項目，但對於決定用戶是否點擊新聞連結的影響卻不顯著。截至目前為止，大多數網友選擇點擊連結的原因在於好奇「跨政治立場（cross-cutting）」內容，其他專家贊同這項研究的同時，也呼籲更多、更廣泛的研究投入。這項新研究的動機備受爭議，過濾功能恐讓臉書用戶接觸到的新聞連結流於一言堂。批評者認為，過濾用戶選擇點擊的新聞內容對民主發展和公眾討論將產生不良影響。「越來越多人在社群網站上發布並轉貼新聞連結和資訊。」臉書數據科學家梅辛（Solomon Messing）說明：「我們希望可以量化人們所分享的、不同立場的新聞內容種類，以及人們在何種程度上會實際閱讀它。」梅辛及其研究團隊研究臉書1010萬名用戶，從其他挑選出9％在個人資料公開政治立場的成人，例如標記自己「自由」或「保守」等。Exposure to Diverse Information on Facebook by Eytan Bakshy, Solomon Messing, Lada Adamic http://t.co/koe1CSQu5C研究人員根據超過20位用戶分享的22萬6000則新聞，給予「政治上的結盟」分數，讓每個人基於這些數據陳述新聞連結中的意識形態，然後再評估對立的政治領域中有多少「跨政治立場」的內容，可以提供給用戶。這份研究報告顯示，有40％到50％的人從臉書隨意點擊連結，然而這些都不是新聞提要演算法算出來的，「因為我們大多數時間只看我們朋友分享的連結」。基於臉書好友分享，用戶可能永遠只會看到29.5％、平常不會自己不會主動關注的「跨政治立場」新聞材料。影響這些百分比的是臉書上介於「自由」或「保守」的用戶群體，臉書研究人員所研究的個案是很清楚的，梅辛指出：「如果你是比較激進的是自由派或保守派，你很容易可以看出，你選擇點進去閱讀的文章比新聞提要演算法提供給你的還要多。」"How Facebook’s Algorithm Suppresses Content Diversity (Modestly) & How the Newsfeed Rules the Clicks" http://t.co/rdSYc6cXbO大多數人們傾向和與自己相似的人當朋友，該研究報告指出，平均而言，有8成臉書用戶的喜好和政治觀點有關，當我們選擇誰來當我們的臉友時，臉書也從中挑選新聞連結觸及給用戶，其中有複雜的、有爭議的、有隱私的，根據這項研究，這個過程將新聞內容進一步交叉篩選掉，但比重僅占28.9％，即使是從新聞提要演算法中獲得連結來源，對比收到的點擊次數：只有24.9％的人會自己點擊以及開拓未經他人轉貼的新聞連結。
          
（相關報導：
臉書未告知情緒實驗 各方撻伐
｜
更多文章
）

梅辛認為，我們選擇的線上好友造成這項的巨大差異，根據基礎研究，透過過濾功能閱讀新聞削減了許多能刺激用戶思考的挑戰性內容。其中，最大且懸而未決的問題是，這是否會使臉書用戶只看到其他網友對新聞事件的回應或立場，而不是直接從自己喜歡的新聞媒體網站獲得新聞資訊。Facebook’s newsfeed algorithm decreases ideologically diverse content http://t.co/B71i12kd32 by @zeynep via @Medium pic.twitter.com/l2CF2rVMjb波士頓東北大學（Northeastern University in Boston）的雷澤爾（David Lazer）博士表示，這是一個尷尬的對比：「我們無法確切掌握臉書是鼓勵還是阻礙政治討論，因為我們在真實世界沒有可以相互對照的數量或質量」，拉茲還說，這個研究是個關鍵議題，也讓世人有「持續保持警惕的必要」。「臉書以公開方式進行這項研究值得信賴，但現在還需要一個更廣泛的、獨立的、世界性的科學家體系來研究這些系統。」Annoyed at Facebook paper. Then I read the intro @davidlazer http://t.co/apKQft3ehA and @zeynep https://t.co/hL2vDxNHeM and feel better.英國牛津大學（University of Oxford）研究社群網路的教授波特（Mason Porter）對此看法類似，他認為下一步將是與其他網路環境比較結果，「這些現象對應在其他社群網站有多少真實性？我認為這將激發更多相關研究。」倫敦大學學院（University College London）統計與電算科學教授沃爾夫（Patrick Wolfe）認為雖然數據有點侷限，但這項研究仍是有趣的，他對研究結果不感到意外。沃爾夫評論，研究對象的偏差可能意味著調查結果未反映大多數人們的使用情形，特別是要得到1000萬用戶，研究人員首先必須排除一週內使用臉書低於4次的30％用戶，以及不主動公開政治立場的91％成人用戶。梅辛博士回應：「我們感興趣的是誰是真正的社群網站用戶群，與用戶的登錄次數並不是真正相關」，他強調團隊有上百萬的觀察者，「誤差應該比圖表上的點還要小。」 
          
（相關報導：
臉書未告知情緒實驗 各方撻伐
｜
更多文章
）

Copyright © 2025 Storm Media Group All Rights Reserved. ◎未經授權．不得轉載